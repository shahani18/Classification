{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a6a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed1d5327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21250780</td>\n",
       "      <td>7.028591e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14102608</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15699</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17358227</td>\n",
       "      <td>1.557482e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102508</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15708</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25035648</td>\n",
       "      <td>1.249146e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102709</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>92f5800b</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21189</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2424</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>100192</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19418340</td>\n",
       "      <td>1.541478e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102518</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>0a742914</td>\n",
       "      <td>510bd839</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20634</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2374</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26160847</td>\n",
       "      <td>1.339255e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102717</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3e2bf98d</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18539</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2104</td>\n",
       "      <td>0</td>\n",
       "      <td>559</td>\n",
       "      <td>-1</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0    21250780  7.028591e+18      1  14102608  1005           0  1fbe01fe   \n",
       "1    17358227  1.557482e+18      0  14102508  1005           0  1fbe01fe   \n",
       "2    25035648  1.249146e+19      0  14102709  1005           0  85f751fd   \n",
       "3    19418340  1.541478e+19      0  14102518  1005           1  0a742914   \n",
       "4    26160847  1.339255e+19      0  14102717  1005           0  85f751fd   \n",
       "\n",
       "  site_domain site_category    app_id  ... device_type device_conn_type  \\\n",
       "0    f3845767      28905ebd  ecad2386  ...           1                0   \n",
       "1    f3845767      28905ebd  ecad2386  ...           1                0   \n",
       "2    c4e18dd6      50e219e0  92f5800b  ...           1                3   \n",
       "3    510bd839      f028772b  ecad2386  ...           1                0   \n",
       "4    c4e18dd6      50e219e0  3e2bf98d  ...           1                0   \n",
       "\n",
       "     C14  C15 C16   C17  C18  C19     C20  C21  \n",
       "0  15699  320  50  1722    0   35      -1   79  \n",
       "1  15708  320  50  1722    0   35      -1   79  \n",
       "2  21189  320  50  2424    1  161  100192   71  \n",
       "3  20634  320  50  2374    3   39      -1   23  \n",
       "4  18539  320  50  2104    0  559      -1  171  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"HW3_click.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "696a76f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8b9af1757ccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Remove the unnecessary columns customerID & UpdatedAt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcleaned_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"6\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"7\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"9\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4305\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4307\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4309\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#Remove the unnecessary columns customerID & UpdatedAt\n",
    "cleaned_df = data.drop(data.columns[\"0\", \"1\", '3' ,\"4\", \"5\", \"6\", \"7\",\"8\", \"9\"], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0dcb671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>C17</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14102608</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14102508</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14102709</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14102518</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>2374</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14102717</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>2104</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour    C1  banner_pos   C17  C21\n",
       "0  14102608  1005           0  1722   79\n",
       "1  14102508  1005           0  1722   79\n",
       "2  14102709  1005           0  2424   71\n",
       "3  14102518  1005           1  2374   23\n",
       "4  14102717  1005           0  2104  171"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = data.drop(data.columns[3], axis=1, inplace=True)\n",
    "cleaned_df = data.drop(data.columns[4], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c070b963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>C15</th>\n",
       "      <th>C17</th>\n",
       "      <th>C19</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14102608</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>1722</td>\n",
       "      <td>35</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14102508</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>1722</td>\n",
       "      <td>35</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14102709</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>2424</td>\n",
       "      <td>161</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14102518</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>2374</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14102717</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>2104</td>\n",
       "      <td>559</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour    C1  banner_pos  C15   C17  C19  C21\n",
       "0  14102608  1005           0  320  1722   35   79\n",
       "1  14102508  1005           0  320  1722   35   79\n",
       "2  14102709  1005           0  320  2424  161   71\n",
       "3  14102518  1005           1  320  2374   39   23\n",
       "4  14102717  1005           0  320  2104  559  171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = data.drop(data.columns[3], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c090c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click                int64\n",
       "hour                 int64\n",
       "C1                   int64\n",
       "banner_pos           int64\n",
       "app_category        object\n",
       "device_id           object\n",
       "device_ip           object\n",
       "device_model        object\n",
       "device_type          int64\n",
       "device_conn_type     int64\n",
       "C14                  int64\n",
       "C15                  int64\n",
       "C16                  int64\n",
       "C17                  int64\n",
       "C18                  int64\n",
       "C19                  int64\n",
       "C20                  int64\n",
       "C21                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f57d691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0ac51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('click',axis='columns')\n",
    "y = data['click']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b94d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e8d91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96596484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>app_category</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_ip</th>\n",
       "      <th>device_model</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79518</th>\n",
       "      <td>14102408</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>8aeb9f8c</td>\n",
       "      <td>b22a3c02</td>\n",
       "      <td>f9ba9057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6991</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>613</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>100233</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180438</th>\n",
       "      <td>14102601</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>09223a78</td>\n",
       "      <td>158e4944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20634</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2374</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100148</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152408</th>\n",
       "      <td>14102320</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8ded1f7a</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>6fa99964</td>\n",
       "      <td>235bcfc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17017</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1873</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23823</th>\n",
       "      <td>14102805</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8ded1f7a</td>\n",
       "      <td>66acfa9b</td>\n",
       "      <td>5fe5ab5b</td>\n",
       "      <td>de19f57c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22681</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2528</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>100076</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194414</th>\n",
       "      <td>14103015</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a03fe903</td>\n",
       "      <td>c7e50844</td>\n",
       "      <td>be87996b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15701</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117886</th>\n",
       "      <td>14102810</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>1b30265b</td>\n",
       "      <td>7ed3c15f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23144</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2665</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100165</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67018</th>\n",
       "      <td>14102405</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>47822fb2</td>\n",
       "      <td>a9a7b3d8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8330</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>100075</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63714</th>\n",
       "      <td>14102309</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>60bab2b1</td>\n",
       "      <td>5ec45883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22137</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1702</td>\n",
       "      <td>0</td>\n",
       "      <td>1059</td>\n",
       "      <td>100075</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166061</th>\n",
       "      <td>14102905</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>c5d6abda</td>\n",
       "      <td>99e427c9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21611</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2480</td>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>100111</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>14102516</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>4bb23fcf</td>\n",
       "      <td>4ceb2e0b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15708</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hour    C1  banner_pos app_category device_id device_ip  \\\n",
       "79518   14102408  1002           0     07d7df22  8aeb9f8c  b22a3c02   \n",
       "180438  14102601  1005           0     07d7df22  a99f214a  09223a78   \n",
       "152408  14102320  1005           0     8ded1f7a  a99f214a  6fa99964   \n",
       "23823   14102805  1005           0     8ded1f7a  66acfa9b  5fe5ab5b   \n",
       "194414  14103015  1005           0     0f2161f8  a03fe903  c7e50844   \n",
       "117886  14102810  1005           0     0f2161f8  a99f214a  1b30265b   \n",
       "67018   14102405  1005           1     07d7df22  a99f214a  47822fb2   \n",
       "63714   14102309  1005           1     07d7df22  a99f214a  60bab2b1   \n",
       "166061  14102905  1005           0     0f2161f8  a99f214a  c5d6abda   \n",
       "21414   14102516  1005           0     07d7df22  a99f214a  4bb23fcf   \n",
       "\n",
       "       device_model  device_type  device_conn_type    C14  C15  C16   C17  \\\n",
       "79518      f9ba9057            0                 0   6991  320   50   613   \n",
       "180438     158e4944            1                 0  20634  320   50  2374   \n",
       "152408     235bcfc1            1                 0  17017  320   50  1873   \n",
       "23823      de19f57c            1                 0  22681  320   50  2528   \n",
       "194414     be87996b            1                 2  15701  320   50  1722   \n",
       "117886     7ed3c15f            1                 0  23144  320   50  2665   \n",
       "67018      a9a7b3d8            1                 0   8330  320   50   761   \n",
       "63714      5ec45883            1                 0  22137  320   50  1702   \n",
       "166061     99e427c9            1                 0  21611  320   50  2480   \n",
       "21414      4ceb2e0b            1                 0  15708  320   50  1722   \n",
       "\n",
       "        C18   C19     C20  C21  \n",
       "79518     2    39  100233   32  \n",
       "180438    3    39  100148   23  \n",
       "152408    3    39      -1   23  \n",
       "23823     0    39  100076  221  \n",
       "194414    0    35      -1   79  \n",
       "117886    0    35  100165  221  \n",
       "67018     3   175  100075   23  \n",
       "63714     0  1059  100075  110  \n",
       "166061    3   297  100111   61  \n",
       "21414     0    35      -1   79  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "746fcf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['hour','C1','device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10bd1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click: [1 0]\n",
      "hour: [0.5503792  0.44203684 0.65980498 0.45287107 0.66847237 0.75839653\n",
      " 0.87215601 0.12892741 0.11700975 0.88190683 0.24160347 0.6695558\n",
      " 0.00975081 0.33261105 0.55362947 0.01083424 0.21885157 0.55904659\n",
      " 0.34344529 0.88624052 0.11375948 0.00866739 0.01408451 0.22751896\n",
      " 0.75947996 0.77248104 0.98266522 0.10942579 0.00650054 0.8808234\n",
      " 0.76814735 0.11809317 0.87973998 0.54387866 0.97508126 0.44095341\n",
      " 0.65872156 0.44853738 0.55579632 0.87540628 0.7616468  0.87323944\n",
      " 0.33802817 0.55146262 0.12459372 0.1191766  0.0227519  0.45070423\n",
      " 0.12676056 0.78223185 0.02166847 0.44637053 0.65005417 0.01516793\n",
      " 0.98808234 0.4496208  0.12351029 0.99133261 1.         0.44420368\n",
      " 0.43770314 0.98483207 0.44528711 0.7659805  0.32502709 0.77681473\n",
      " 0.77031419 0.21993499 0.78114843 0.98699892 0.87107259 0.00433369\n",
      " 0.34994583 0.76706392 0.65655471 0.76923077 0.77789816 0.00325027\n",
      " 0.55471289 0.12134345 0.97616468 0.87432286 0.23293608 0.54821235\n",
      " 0.22426869 0.22643554 0.98049837 0.22535211 0.56013001 0.11267606\n",
      " 0.67497291 0.01191766 0.3347779  0.33911159 0.66738895 0.99349946\n",
      " 0.76056338 0.77573131 0.66413868 0.01950163 0.23726977 0.12784399\n",
      " 0.45178765 0.33694475 0.88299025 0.34127844 0.99566631 0.1148429\n",
      " 0.87757313 0.56338028 0.76381365 0.12026002 0.55796316 0.76273023\n",
      " 0.77464789 0.34019502 0.23510293 0.12567714 0.11050921 0.55687974\n",
      " 0.67280607 0.55254605 0.45612134 0.56229686 0.99241603 0.00541712\n",
      " 0.23943662 0.98916576 0.88840737 0.         0.34452871 0.0184182\n",
      " 0.8851571  0.87648971 0.22860238 0.12242687 0.11592633 0.77898158\n",
      " 0.24052004 0.01733478 0.32611051 0.54496208 0.2340195  0.00758397\n",
      " 0.22210184 0.23185265 0.67172264 0.22101842 0.99674973 0.44745395\n",
      " 0.3304442  0.44312026 0.65547129 0.32936078 0.66630553 0.54712893\n",
      " 0.99024919 0.43986999 0.66197183 0.86673889 0.56663055 0.54279523\n",
      " 0.43878657 0.34236186 0.77356446 0.66088841 0.77139762 0.00108342\n",
      " 0.2383532  0.33369447 0.56446371 0.97941495 0.23618635 0.65438787\n",
      " 0.22968581 0.33586132 0.13001083 0.99783315 0.89165764 0.65763814\n",
      " 0.97833153 0.88407367 0.02058505 0.54929577 0.22318527 0.32827736\n",
      " 0.78331528 0.23076923 0.67388949 0.78006501 0.34669556 0.87865655\n",
      " 0.13109426 0.56554713 0.86890574 0.01300108 0.45503792 0.9772481\n",
      " 0.6652221  0.66305525 0.01625135 0.98591549 0.65330444 0.86998917\n",
      " 0.99458288 0.32719393 0.21668472 0.9815818  0.99891658 0.10834236\n",
      " 0.02491874 0.45828819 0.11159263 0.43336945 0.76489707 0.02383532\n",
      " 0.00216685 0.4539545  0.56121343 0.86782232 0.65222102 0.88732394\n",
      " 0.21776815 0.43661972 0.33152763 0.88949079 0.65113759 0.98374865\n",
      " 0.43445287 0.43553629 0.34561213 0.54171181 0.5460455  0.89057421\n",
      " 0.67063922 0.13217768 0.13326111 0.45720477 0.34886241 0.34777898]\n",
      "C1: [0.36363636 0.81818182 0.09090909 0.54545455 1.         0.63636364\n",
      " 0.        ]\n",
      "banner_pos: [0 1 7 5 3 2 4]\n",
      "device_type: [1 4 0 5]\n",
      "device_conn_type: [0.  0.6 0.4 1. ]\n",
      "C14: [0.64745648 0.64783674 0.87941524 ... 0.94976339 0.9371303  0.76432314]\n",
      "C15: [0.22123894 0.19911504 0.10619469 1.         0.39823009 0.67256637\n",
      " 0.         0.71681416]\n",
      "C16: [0.02988048 0.22908367 0.01593625 0.45816733 0.74501992 0.29880478\n",
      " 0.06972112 0.         1.        ]\n",
      "C17: [0.60869565 0.87410208 0.85519849 0.75311909 0.9100189  0.91153119\n",
      " 0.90510397 0.98903592 0.83969754 0.11758034 0.84650284 0.90359168\n",
      " 0.53459357 0.89035917 0.96483932 0.8952741  0.8415879  0.90775047\n",
      " 0.63818526 0.90018904 0.94706994 0.90548204 0.91342155 0.97277883\n",
      " 0.79962193 0.78979206 0.82192817 0.39659735 0.96521739 0.91266541\n",
      " 0.97807183 0.6657845  0.73648393 0.24536862 0.8268431  0.71115312\n",
      " 0.66540643 0.62646503 0.9073724  0.66200378 0.91984877 0.97391304\n",
      " 0.91190926 0.96937618 0.28393195 0.71153119 0.97353497 0.85406427\n",
      " 0.9610586  0.92249527 0.70359168 0.9584121  0.97164461 0.94669187\n",
      " 0.84536862 0.6710775  0.72741021 0.82079395 0.82533081 0.83591682\n",
      " 0.         0.13875236 0.97655955 0.98185255 0.95425331 0.02495274\n",
      " 0.60113422 0.99621928 0.16332703 0.17391304 0.70396975 0.93043478\n",
      " 0.40151229 0.8120983  0.8389414  0.99432892 0.80529301 0.92778828\n",
      " 0.93005671 0.98109641 0.99206049 0.61587902 0.9047259  0.92551985\n",
      " 0.92173913 0.88355388 0.90094518 0.95916824 0.96635161 0.98827977\n",
      " 0.82003781 0.5047259  0.97240076 0.89981096 0.97126654 0.96257089\n",
      " 0.72854442 0.90434783 0.3705104  0.87258979 0.27221172 0.89943289\n",
      " 0.73005671 0.82381853 0.90056711 0.90132325 0.96748582 0.98752363\n",
      " 0.8094518  0.92060491 0.77504726 0.96597353 0.97504726 0.9020794\n",
      " 0.00378072 0.83327032 0.99659735 0.66918715 0.78223062 0.89451796\n",
      " 0.99697543 0.16446125 0.68393195 0.68884688 0.97088847 0.9168242\n",
      " 0.9342155  0.83175803 0.85330813 0.67410208 0.94404537 0.94971645\n",
      " 0.94820416 0.97202268 0.17353497 0.99886578 0.84234405 0.67561437\n",
      " 0.98374291 0.87977316 0.94782609 0.94102079 0.98449905 0.98487713\n",
      " 0.98601134 0.98638941 0.9463138  0.81625709 0.30018904 0.62003781\n",
      " 0.24801512 0.77353497 0.88015123 0.4294896  0.9826087  0.43856333\n",
      " 0.86275992 0.94139887 0.95538752 0.90170132 0.92022684 0.27032136\n",
      " 0.88128544 0.95009452 0.93761815 0.16521739 0.81361059 0.9194707\n",
      " 0.91115312 0.91606805 0.64688091 0.96219282 0.69678639 0.97769376\n",
      " 0.936862   0.89603025 0.95085066 0.63062382 0.98147448 0.8778828\n",
      " 0.91909263 0.92930057 0.64612476 0.85444234 0.9436673  0.99281664\n",
      " 0.98336484 0.99924386 0.77202268 0.80037807 0.71228733 0.93950851\n",
      " 0.96143667 0.81890359 0.93194707 0.83667297 0.95879017 0.29716446\n",
      " 0.92589792 0.88241966 0.95765595 0.89376181 0.01550095 0.49678639\n",
      " 0.48733459 0.931569   0.94026465 0.92400756 0.87448015 0.8979206\n",
      " 0.95614367 0.92325142 0.57655955 0.68582231 0.17542533 0.95500945\n",
      " 0.29829868 0.10661626 0.89716446 0.69073724 0.93308129 0.18941399\n",
      " 0.94291115 0.95954631 0.82155009 0.91758034 0.65141777 0.88582231\n",
      " 0.90283554 0.82835539 0.92098299 0.90850662 0.91493384 0.84196597\n",
      " 0.87599244 0.98865784 0.79886578 0.82117202 0.53534972 0.94442344\n",
      " 0.90623819 0.77466919 0.9557656  0.99357278 0.71039698 0.95803403\n",
      " 0.89867675 0.89565217 0.92287335 0.59810964 0.94064272 0.31190926\n",
      " 0.96068053 0.93232514 0.77164461 0.9289225  0.91531191 0.61550095\n",
      " 0.78449905 0.95727788 0.91039698 0.82041588 0.03175803 0.96672968\n",
      " 0.99962193 0.98298677 0.8805293  0.8241966  0.88544423 0.94215501\n",
      " 0.91568998 0.21701323 0.96786389 0.36446125 0.82873346 0.93724008\n",
      " 0.82986767 0.98979206 0.99168242 0.99395085 0.87183365 0.99546314\n",
      " 0.96446125 0.88846881 0.78903592 0.90586011 0.93648393 0.91455577\n",
      " 0.71720227 0.69338374 0.63213611 0.16559546 0.96975425 0.69867675\n",
      " 0.92476371 0.96559546 0.98223062 0.99470699 0.90396975 0.94328922\n",
      " 0.95689981 0.67712665 0.79924386 0.9879017  0.9221172  0.95463138\n",
      " 0.93270321 0.89187146 0.95349716 0.98071834 0.92741021 0.6415879\n",
      " 0.87561437 0.98412098 0.93345936 0.96332703 0.94480151 0.95652174\n",
      " 0.94517958 0.95236295 0.96181474 0.35160681 0.96824197 0.9637051\n",
      " 0.87939509 0.66994329 0.95387524 0.86956522 0.99848771 0.74517958\n",
      " 0.91871456 0.93572779 0.82306238 0.94555766 0.93837429 0.96899811\n",
      " 0.80831758 0.59470699 0.91417769 0.87826087 0.87863894 0.92967864\n",
      " 0.90964083 0.92362949 0.91228733 0.70056711 0.39621928 0.89640832\n",
      " 0.87296786 0.96408318 0.86389414 0.59962193 0.87523629 0.98941399\n",
      " 0.88506616 0.81323251 0.28771267 0.37618147 0.96030246 0.8294896\n",
      " 0.71984877 0.33875236 0.88393195 0.96294896 0.92438563 0.68809074\n",
      " 0.9705104  0.95311909 0.92665406 0.52741021 0.98034026 0.94177694\n",
      " 0.97920605 0.39206049 0.7705104  0.90661626 0.91644612 0.43213611\n",
      " 0.93081285 0.70321361 0.96710775 0.86124764 0.81928166 0.9731569\n",
      " 0.91304348 0.94593573 0.93610586 0.88733459 0.79621928 0.97844991\n",
      " 0.81587902 0.38903592 0.91833648 0.97958412 0.95198488 0.79168242\n",
      " 0.93799622 0.75198488 0.89489603 0.93988658 0.96862004 0.8831758\n",
      " 1.         0.97429112 0.88431002 0.97013233 0.28733459]\n",
      "C18: [0.         0.33333333 1.         0.66666667]\n",
      "C19: [1.10741971e-03 7.08748616e-02 3.32225914e-03 2.91251384e-01\n",
      " 7.19822813e-02 1.42303433e-01 7.53045404e-02 7.41971207e-02\n",
      " 1.46179402e-01 0.00000000e+00 4.99446290e-01 2.18161683e-01\n",
      " 5.53709856e-04 7.86267996e-02 7.16500554e-01 5.70321152e-01\n",
      " 3.57696567e-01 3.54374308e-01 1.49501661e-01 1.47286822e-01\n",
      " 2.20376523e-01 7.64119601e-02 2.86821705e-01 2.13732004e-01\n",
      " 7.75193798e-03 3.62126246e-01 7.12070875e-01 5.68106312e-01\n",
      " 1.42857143e-01 4.42967885e-03 5.00553710e-01 5.53709856e-03\n",
      " 2.84606866e-01 4.26356589e-01 2.76854928e-03 4.30786268e-01\n",
      " 4.33001107e-01 4.29678848e-01 3.58803987e-01 1.45071982e-01\n",
      " 7.85160576e-01 5.74750831e-01 5.71428571e-01 3.55481728e-01\n",
      " 9.29125138e-01 4.31893688e-01 4.25249169e-01 8.53820598e-01\n",
      " 7.09856035e-01 2.15946844e-01 2.17054264e-01 2.87929125e-01\n",
      " 1.00000000e+00 5.03875969e-01 9.95570321e-01 9.97785161e-01\n",
      " 2.89036545e-01 2.12624585e-01 5.01661130e-01 8.58250277e-01\n",
      " 7.82945736e-01 1.41749723e-01 6.64451827e-03 3.59911406e-01]\n",
      "C20: [0.         0.99944139 0.99836407 0.99945137 0.99828427 0.99900248\n",
      " 0.99772566 0.9983541  0.9986334  0.99829425 0.99833415 0.9982743\n",
      " 0.99973067 0.9983142  0.99826432 0.99846383 0.99928179 0.99857355\n",
      " 0.99883291 0.99969077 0.99940149 0.99954114 0.99786532 0.99929176\n",
      " 0.99757604 0.99882293 0.99806482 0.99755609 0.99771569 0.99951122\n",
      " 0.99908229 0.99942144 0.99907231 0.99922194 0.99864338 0.99933166\n",
      " 0.99941147 0.99811469 0.99934164 0.99912219 0.99896258 0.99765584\n",
      " 0.99774561 0.99783539 0.99816457 0.99880298 0.99780546 0.99943142\n",
      " 0.99858353 0.99756606 0.99813464 0.99923191 0.99952119 0.99946134\n",
      " 0.99920199 0.99817455 0.99924189 0.9985137  0.99903241 0.99918204\n",
      " 0.99807479 0.99752616 0.99865335 0.99985037 0.99914214 0.99893266\n",
      " 0.99812467 0.99840397 0.99977057 0.9987132  0.99993017 0.9981546\n",
      " 0.99809474 0.99869325 0.99853365 0.9998005  0.99962094 0.99925186\n",
      " 0.99773564 0.9985536  0.99895261 0.99804487 0.99798502 0.99791519\n",
      " 0.99904238 0.9985935  0.99964089 0.99820447 0.99800497 0.99848378\n",
      " 0.99885286 0.99802492 0.99866333 0.998394   0.99935161 0.99947132\n",
      " 0.99824437 0.99814462 0.99937156 0.99792517 0.99901246 0.99805484\n",
      " 0.99891271 0.99913216 0.99876308 0.99810472 0.99902243 0.99822442\n",
      " 0.99764586 0.99793514 0.99784537 1.         0.99768576 0.99838402\n",
      " 0.99803489 0.99873315 0.99778551 0.99845385 0.99801494 0.99981047\n",
      " 0.9984339  0.99789524 0.99967082 0.99808477 0.99917206 0.99849375\n",
      " 0.99957107 0.99754611 0.9982344  0.99931171 0.99889276 0.99842392\n",
      " 0.99781544 0.99958104 0.99834412 0.99795509 0.9987531  0.99878303\n",
      " 0.99762591 0.99776556 0.99785534 0.99777554 0.9984738  0.99753614\n",
      " 0.99921196 0.9997606  0.99915211 0.99825435 0.99965087 0.9999601\n",
      " 0.99874313 0.99887281 0.99860348 0.99930174 0.99850373 0.99861345]\n",
      "C21: [0.30708661 0.27559055 0.08661417 0.66929134 0.86614173 0.61417323\n",
      " 0.16141732 0.12204724 0.23622047 0.13385827 0.19685039 0.26377953\n",
      " 0.45669291 0.83070866 0.18503937 0.16535433 0.2007874  0.12598425\n",
      " 0.39370079 0.3503937  0.17716535 0.61023622 0.37007874 0.05511811\n",
      " 0.27165354 0.42913386 0.29527559 0.69685039 0.35433071 0.06299213\n",
      " 0.96456693 0.38976378 0.7992126  0.8976378  0.04724409 0.43307087\n",
      " 0.26771654 0.75984252 0.43700787 0.99212598 0.05905512 0.42125984\n",
      " 0.62204724 0.31889764 0.45275591 0.71259843 0.36220472 0.07480315\n",
      " 0.36614173 0.98425197 0.76377953 1.         0.3976378  0.63779528\n",
      " 0.69291339 0.49212598 0.40551181 0.         0.33070866 0.85826772]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aba0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('click',axis='columns')\n",
    "y = df['click']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7550076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    116209\n",
       "1     23791\n",
       "Name: click, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e91780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    165972\n",
       "1     34028\n",
       "Name: click, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d11f4494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79518</th>\n",
       "      <td>0.333694</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.189414</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.122047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180438</th>\n",
       "      <td>0.542795</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.855198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.086614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152408</th>\n",
       "      <td>0.238353</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703143</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23823</th>\n",
       "      <td>0.763814</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942454</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.913422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.998284</td>\n",
       "      <td>0.866142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194414</th>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117886</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962016</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.965217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.999172</td>\n",
       "      <td>0.866142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67018</th>\n",
       "      <td>0.330444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336108</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.245369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078627</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>0.086614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63714</th>\n",
       "      <td>0.226436</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919469</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.601134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568106</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>0.429134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166061</th>\n",
       "      <td>0.872156</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897245</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.895274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146179</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.236220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647837</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.02988</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hour        C1  banner_pos  device_type  device_conn_type  \\\n",
       "79518   0.333694  0.090909           0            0               0.0   \n",
       "180438  0.542795  0.363636           0            1               0.0   \n",
       "152408  0.238353  0.363636           0            1               0.0   \n",
       "23823   0.763814  0.363636           0            1               0.0   \n",
       "194414  0.991333  0.363636           0            1               0.4   \n",
       "117886  0.769231  0.363636           0            1               0.0   \n",
       "67018   0.330444  0.363636           1            1               0.0   \n",
       "63714   0.226436  0.363636           1            1               0.0   \n",
       "166061  0.872156  0.363636           0            1               0.0   \n",
       "21414   0.450704  0.363636           0            1               0.0   \n",
       "\n",
       "             C14       C15      C16       C17       C18       C19       C20  \\\n",
       "79518   0.279534  0.221239  0.02988  0.189414  0.666667  0.003322  0.999850   \n",
       "180438  0.855966  0.221239  0.02988  0.855198  1.000000  0.003322  0.999002   \n",
       "152408  0.703143  0.221239  0.02988  0.665784  1.000000  0.003322  0.000000   \n",
       "23823   0.942454  0.221239  0.02988  0.913422  0.000000  0.003322  0.998284   \n",
       "194414  0.647541  0.221239  0.02988  0.608696  0.000000  0.001107  0.000000   \n",
       "117886  0.962016  0.221239  0.02988  0.965217  0.000000  0.001107  0.999172   \n",
       "67018   0.336108  0.221239  0.02988  0.245369  1.000000  0.078627  0.998274   \n",
       "63714   0.919469  0.221239  0.02988  0.601134  0.000000  0.568106  0.998274   \n",
       "166061  0.897245  0.221239  0.02988  0.895274  1.000000  0.146179  0.998633   \n",
       "21414   0.647837  0.221239  0.02988  0.608696  0.000000  0.001107  0.000000   \n",
       "\n",
       "             C21  \n",
       "79518   0.122047  \n",
       "180438  0.086614  \n",
       "152408  0.086614  \n",
       "23823   0.866142  \n",
       "194414  0.307087  \n",
       "117886  0.866142  \n",
       "67018   0.086614  \n",
       "63714   0.429134  \n",
       "166061  0.236220  \n",
       "21414   0.307087  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86209a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bd334",
   "metadata": {},
   "source": [
    "# Question#2 part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20613c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaab696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = model.score(X_test, y_test)\n",
    "    print(\"Accuracy\", acc, \"\\n\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"preds\", y_pred[:10], \"\\n\")\n",
    "    \n",
    "    R2 = r2_score(y_test,y_pred)\n",
    "    print(\"R2 Score\", R2, \"\\n\")\n",
    "\n",
    "    cl_rep = classification_report(y_test,y_pred)\n",
    "    print(cl_rep)\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f86091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8281166666666666 \n",
      "\n",
      "preds [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "\n",
      "R2 Score -0.21466637865239524 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     49763\n",
      "           1       0.18      0.00      0.00     10237\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.50      0.50      0.45     60000\n",
      "weighted avg       0.72      0.83      0.75     60000\n",
      "\n",
      "Confusion Matrix : \n",
      "[[49666    97]\n",
      " [10216    21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# # pass -1 to use Logistics Regression without weights\n",
    "log_reg(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d772d",
   "metadata": {},
   "source": [
    "# part b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec2e90e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=50, max_iter=100, tol=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model    # L1 regularization\n",
    "\n",
    "lasso_reg = linear_model.Lasso(alpha = 50, max_iter = 100, tol = 1)\n",
    "lasso_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "322bdf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.2768512598924104e-06"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da98c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97041bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score -3.2768512598924104e-06 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "R2 = r2_score(y_test,y_pred)\n",
    "print(\"R2 Score\", R2, \"\\n\")\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a819ea",
   "metadata": {},
   "source": [
    "# L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1964a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=50, max_iter=100, tol=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg = linear_model.RidgeClassifier(alpha = 50, max_iter = 100, tol = 1)\n",
    "ridge_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204fc90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282333333333334"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46b8c189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289714285714286"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0244f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge_reg.predict(X_test)\n",
    "print(\"preds\", y_pred[:20], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a62c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     49763\n",
      "           1       0.15      0.00      0.00     10237\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.49      0.50      0.45     60000\n",
      "weighted avg       0.71      0.83      0.75     60000\n",
      "\n",
      "R2 Score -0.21384191781165374 \n",
      "\n",
      "Confusion Matrix : \n",
      "[[49679    84]\n",
      " [10222    15]]\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test,y_pred)\n",
    "print(cl_rep)\n",
    "R2 = r2_score(y_test,y_pred)\n",
    "print(\"R2 Score\", R2, \"\\n\")\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433a35c",
   "metadata": {},
   "source": [
    "# after L2 \n",
    "regularization accuracy is little bit improved as shown in the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd5c30",
   "metadata": {},
   "source": [
    "# Part C: K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b678e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [0.83092857 0.83121429 0.82617857 0.82639286 0.82935714]\n",
      "Average Cross Validation score :0.8288142857142857\n",
      "Confusion Matrix : \n",
      "[[49666    97]\n",
      " [10216    21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "kf=KFold(n_splits=5)\n",
    "score=cross_val_score(model,X_train,y_train,cv=kf)\n",
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))\n",
    "\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b50a2",
   "metadata": {},
   "source": [
    "# Part d: Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b25d7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('click',axis='columns')\n",
    "y = df['click']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50cc3ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8281166666666666\n",
      "Precision Score : 0.17796610169491525\n",
      "Recall Score : 0.002051382240890886\n",
      "F1 Score : 0.004056011588604538\n",
      "R2 Score : -0.21466637865239524\n",
      "Confusion Matrix : \n",
      "[[49666    97]\n",
      " [10216    21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Evaluation metrics \n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
    "print('R2 Score : ' + str(r2_score(y_test,y_pred)))\n",
    "\n",
    "\n",
    "#Logistic Regression Classifier Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0014b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [           nan 0.00000000e+00            nan 0.00000000e+00\n",
      "            nan 4.20344683e-05            nan 2.47989231e-03\n",
      "            nan 3.19444294e-03            nan 3.15240847e-03\n",
      "            nan 3.19444294e-03            nan 3.15240847e-03]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8281166666666666\n",
      "Precision Score : 0.17796610169491525\n",
      "Recall Score : 0.002051382240890886\n",
      "F1 Score : 0.004056011588604538\n",
      "R2 Score : -0.21466637865239524\n",
      "Confusion Matrix : \n",
      "[[49666    97]\n",
      " [10216    21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = LogisticRegression()\n",
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\n",
    "grid_clf_acc.fit(X_train, y_train)\n",
    "\n",
    "#Predict values based on new parameters\n",
    "y_pred_acc = grid_clf_acc.predict(X_test)\n",
    "\n",
    "# New Model Evaluation metrics \n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))\n",
    "print('R2 Score : ' + str(r2_score(y_test,y_pred_acc)))\n",
    "\n",
    "\n",
    "#Logistic Regression (Grid Search) Confusion matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fabeedb",
   "metadata": {},
   "source": [
    "# Question 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fd9e325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.05336551, 1.10673102, 1.16009652, 1.21346203,\n",
       "       1.26682754, 1.32019305, 1.37355856, 1.42692407, 1.48028957,\n",
       "       1.53365508, 1.58702059, 1.6403861 , 1.69375161, 1.74711711,\n",
       "       1.80048262, 1.85384813, 1.90721364, 1.96057915, 2.01394465,\n",
       "       2.06731016, 2.12067567, 2.17404118, 2.22740669, 2.2807722 ,\n",
       "       2.3341377 , 2.38750321, 2.44086872, 2.49423423, 2.54759974,\n",
       "       2.60096524, 2.65433075, 2.70769626, 2.76106177, 2.81442728,\n",
       "       2.86779279, 2.92115829, 2.9745238 , 3.02788931, 3.08125482,\n",
       "       3.13462033, 3.18798583, 3.24135134, 3.29471685, 3.34808236,\n",
       "       3.40144787, 3.45481338, 3.50817888, 3.56154439, 3.6149099 ,\n",
       "       3.66827541, 3.72164092, 3.77500642, 3.82837193, 3.88173744,\n",
       "       3.93510295, 3.98846846, 4.04183396, 4.09519947, 4.14856498,\n",
       "       4.20193049, 4.255296  , 4.30866151, 4.36202701, 4.41539252,\n",
       "       4.46875803, 4.52212354, 4.57548905, 4.62885455, 4.68222006,\n",
       "       4.73558557, 4.78895108, 4.84231659, 4.8956821 , 4.9490476 ,\n",
       "       5.00241311, 5.05577862, 5.10914413, 5.16250964, 5.21587514,\n",
       "       5.26924065, 5.32260616, 5.37597167, 5.42933718, 5.48270268,\n",
       "       5.53606819, 5.5894337 , 5.64279921, 5.69616472, 5.74953023,\n",
       "       5.80289573, 5.85626124, 5.90962675, 5.96299226, 6.01635777,\n",
       "       6.06972327, 6.12308878, 6.17645429, 6.2298198 , 6.28318531])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(2, 2 * np.pi, 100)\n",
    "y = np.linspace(1, 2*np.pi, 100)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "24cd2f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "abs(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae038c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.randint(0,20, size=(20,20))\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23bdfd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisdict = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f452a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964\n"
     ]
    }
   ],
   "source": [
    "print(thisdict[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63b085f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = ['1', '2', '23', '34', '87']\n",
    "array[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817548d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
